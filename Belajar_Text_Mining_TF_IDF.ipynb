{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Belajar Text Mining - TF-IDF.ipynb",
      "provenance": [],
      "mount_file_id": "1gBtK5vknBBbEDWHDj6qFXQm7TWB6zssn",
      "authorship_tag": "ABX9TyPRlSx+bIlP03Z3GvLcDKg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ianz88/text-mining/blob/master/Belajar_Text_Mining_TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVQJxfWaUxLF",
        "colab_type": "text"
      },
      "source": [
        "# Berkenalan dengan TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-izQnGujVGAo",
        "colab_type": "text"
      },
      "source": [
        "Kita akan belajar untuk:\n",
        "\n",
        "\n",
        "1.   Melakukan text preprocessing dalam bahasa Indonesia\n",
        "2.   Menghitung TF-IDF dengan TfidfVectorizer\n",
        "3.   Melihat data dengan Pandas Dataframe\n",
        "4.   Fine tuning stopwords\n",
        "5.   Melihat term penting dalam dokumen\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzx5rob6WH_r",
        "colab_type": "text"
      },
      "source": [
        "## Persiapan environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk-QaY9JWb1V",
        "colab_type": "text"
      },
      "source": [
        "Install beberapa library dan package yang diperlukan dalam project (dijalankan dalam Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlLW2imCWbRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Library corpus bahasa Indonesia (Sastrawi)\n",
        "!pip install sastrawi \n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# Natural Language Tool Kit (NLTK)\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Python Regex\n",
        "import re\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGdgSYzQYNOa",
        "colab_type": "text"
      },
      "source": [
        "## Persiapan Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFRKwkrqYXF-",
        "colab_type": "text"
      },
      "source": [
        "Fungsi-fungsi yang digunakan untuk mempersiapkan dokumen (teks) yang akan diolah.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywNXKDsHV9qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fungsi memecah dokumen menjadi token (array elemen per kata)\n",
        "def tokenize_clean(text):\n",
        "    \n",
        "    #tokenisasi\n",
        "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word\n",
        "        in nltk.word_tokenize(sent)]\n",
        "    \n",
        "    #clean token from numeric and other character like puntuation\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token) and token not in stopwords:\n",
        "            filtered_tokens.append(token)\n",
        "            \n",
        "    return filtered_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHRmfDlkee19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Daftar Stopwords\n",
        "stopwords_all = nltk.corpus.stopwords.words('indonesian')\n",
        "stopwords_tambahan = {\"ya\",\"yak\",\"iya\",\"yg\",\"ga\",\"gak\",\"gk\",\"udh\",\"sdh\",\"udah\",\"dah\",\"nih\",\"ini\",\"deh\",\"sih\",\"dong\",\"donk\",\n",
        "                 \"sm\",\"knp\",\"utk\",\"yaa\",\"tdk\",\"gini\",\"gitu\",\"bgt\",\"gt\",\"nya\",\"kalo\",\"cb\",\"jg\",\"jgn\",\"gw\",\"ge\",\n",
        "                 \"sy\",\"min\",\"mas\",\"mba\",\"mbak\",\"pak\",\"kak\",\"trus\",\"trs\",\"bs\",\"bisa\",\"aja\",\"saja\",\"no\",\n",
        "                 \"w\",\"g\",\"gua\",\"gue\",\"emang\",\"emg\",\"wkwk\",\"dr\",\"kau\",\"dg\",\"gimana\",\"apapun\",\"apa\",\n",
        "                 \"klo\",\"yah\",\"banget\",\"pake\",\"terus\",\"krn\",\"jadi\",\"jd\",\"mu\",\"ku\",\"si\",\"hehe\",\n",
        "                 \"tp\",\"pa\",\"lu\",\"lo\",\"lw\",\"tw\",\"tau\",\"karna\",\"kayak\",\"ky\",\"lg\",\"untuk\",\"tuk\",\"dg\",\"dgn\"\n",
        "                }\n",
        "stopwords_all.extend(stopwords_tambahan)\n",
        "stopwords = stopwords_all\n",
        "print(len(stopwords))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HJ0QGBzYqwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fungsi menghilangkan stopwords dan tanda baca\n",
        "def remove_stopwords(tokenized_text):\n",
        "    \n",
        "    cleaned_token = []\n",
        "    for token in tokenized_text:\n",
        "        if token not in stopwords:\n",
        "            cleaned_token.append(token)\n",
        "            \n",
        "    return cleaned_token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM5xTSIiYrK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fungsi mengubah kata ke bentuk kata dasar (bahasa Indonesia)\n",
        "def stemming_text(tokenized_text):\n",
        "    \n",
        "    #stem using Sastrawi StemmerFactory \n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "\n",
        "    stems = []\n",
        "    for token in tokenized_text:\n",
        "        stems.append(stemmer.stem(token))\n",
        "\n",
        "    return stems"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-vbcPlOY9TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fungsi preprocessing\n",
        "def text_preprocessing(text):\n",
        "    \n",
        "    prep01 = tokenize_clean(text)\n",
        "    prep02 = remove_stopwords(prep01)\n",
        "    prep03 = stemming_text(prep02)\n",
        "    \n",
        "    return prep03\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mbQMSh-ZlzQ",
        "colab_type": "text"
      },
      "source": [
        "## Step 01 : Tentukan Set Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opYW8pmkZwUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = []\n",
        "files = open('sample_data/diarium3.txt', encoding=\"utf8\").read().split('\\n')\n",
        "\n",
        "#files.append(\"Sekelompok ibu dan kaum perempuan duduk beralaskan rumput lapangan sambil fokus menganyam bambu yang ia genggam di tangan.\")\n",
        "#files.append(\"Sebagian besar masyarakat rupanya tak mau melewatkan waktu begitu  saja untuk meratapi erupsi.\")\n",
        "#files.append(\"Lombok memang memiliki sejuta pesona yang mampu menyedot perhatian orang untuk datang berwisata.\")\n",
        "#files.append(\"Perempuan yang bergelut di dunia kerelawanan akan belajar caranya bertanggung jawab bagi sendiri dan orang lain.\")\n",
        "#files.append(\"Kami berkoordinasi dan melapor pada posko relawan, kami berkomitmen  siap membantu dengan siaga 24 jam\")\n",
        "\n",
        "len(files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YllbKtpAbzY2",
        "colab_type": "text"
      },
      "source": [
        "## Step 02 : Membentuk Corpus Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIf2f0gUae66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Persiapan corpus, load ke dalam dictionary\n",
        "token_dict = {}\n",
        "i = 0\n",
        "for t in files:\n",
        "    filename = \"file\" + str(i)\n",
        "    token_dict[filename] = t\n",
        "    i = i + 1\n",
        "\n",
        "len(token_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0z8uZJKb_IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict.values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9i5-uUDcCEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict['file0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8M2xc45c1L3",
        "colab_type": "text"
      },
      "source": [
        "## Step 03 : Menghitung TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM8eLiUE81Rc",
        "colab_type": "text"
      },
      "source": [
        "TF-IDF (term frequency–inverse document frequency) adalah nilai perhitungan statistik yang mencerminkan seberapa pentingnya sebuah kata dalam suatu dokumen, terhadap semua kumpulan dokumen yang ada.\n",
        "\n",
        "Makin kecil nilai TF-IDF, makin sering kata tersebut muncul dalam dokumen. Bisa juga sebagai indikasi kata tersebut kurang penting.\n",
        "\n",
        "Makin besar nilai TF-IDF, makin jarang kata muncul. Kemungkinan kata tersebut adalah topik yang penting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEL1Mfobc5A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perform tf-idf vectorization\n",
        "tfidf = TfidfVectorizer(max_df=0.8,             # terms with document frequency value > 0.8 will be removed (terlalu sering muncul)\n",
        "                        min_df=0.01,           # terms with document frequency value < 0.02 will be removed (terlalu jarang)\n",
        "                        max_features=200000,    # create maximum 200.000 vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
        "                        stop_words = stopwords, # stopwords list\n",
        "                        use_idf=True,           # enable inverse-document-frequency reweighting\n",
        "                        tokenizer=text_preprocessing, # override the string tokenization step by using text_prepocessing function \n",
        "                        ngram_range=(1,2))      # ngram range 1 - 2 (unigram=1, bigram=2, trigram=3)\n",
        "\n",
        "tfs = tfidf.fit_transform(token_dict.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwowU7SxoTC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perform tf-idf vectorization\n",
        "tfidf22 = TfidfVectorizer(max_df=0.8,             # terms with document frequency value > 0.8 will be removed (terlalu sering muncul)\n",
        "                        min_df=0.008,           # terms with document frequency value < 0.008 will be removed (terlalu jarang)\n",
        "                        max_features=200000,    # create maximum 200.000 vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
        "                        stop_words = stopwords, # stopwords list\n",
        "                        use_idf=True,           # enable inverse-document-frequency reweighting\n",
        "                        tokenizer=text_preprocessing, # override the string tokenization step by using text_prepocessing function \n",
        "                        ngram_range=(2,2))      # ngram range 1 - 2 (unigram=1, bigram=2, trigram=3)\n",
        "\n",
        "tfs22 = tfidf22.fit_transform(token_dict.values())\n",
        "\n",
        "#perform tf-idf vectorization\n",
        "tfidf23 = TfidfVectorizer(max_df=0.8,             # terms with document frequency value > 0.8 will be removed (terlalu sering muncul)\n",
        "                        min_df=0.006,           # terms with document frequency value < 0.006 will be removed (terlalu jarang)\n",
        "                        max_features=200000,    # create maximum 200.000 vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
        "                        stop_words = stopwords, # stopwords list\n",
        "                        use_idf=True,           # enable inverse-document-frequency reweighting\n",
        "                        tokenizer=text_preprocessing, # override the string tokenization step by using text_prepocessing function \n",
        "                        ngram_range=(2,3))      # ngram range 1 - 2 (unigram=1, bigram=2, trigram=3)\n",
        "\n",
        "tfs23 = tfidf23.fit_transform(token_dict.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hw5zKi1eS-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cek tabel perhitungan. Tabel berisi rows=jumlah dokumen, columns=jumlah kata\n",
        "print(\"tfs12 : \",tfs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujCpJ7akf1av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lihat hasil proses\n",
        "feature_names = tfidf.get_feature_names()\n",
        "print('Jumlah n-gram relevan: ', len(feature_names))\n",
        "print('n-gram temuan: ', feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOuWTg0rgUSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# print idf values\n",
        "df_idf = pd.DataFrame(tfidf.idf_, index=feature_names,columns=[\"tf-idf\"])\n",
        "\n",
        "# sort ascending\n",
        "df_idf = df_idf.sort_values(by=['tf-idf'])\n",
        "\n",
        "print(df_idf)\n",
        "#print(df_idf.head())\n",
        "#print(df_idf.tail(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9fuKaRfgwRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
        "# print(df_idf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7mAq6pVsMaN",
        "colab_type": "text"
      },
      "source": [
        "Bandingkan dengan hasil n-gram 2 dan 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNpm2brusRBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cek tabel perhitungan. Tabel berisi rows=jumlah dokumen, columns=jumlah kata\n",
        "print(\"tfs12 : \",tfs.shape)\n",
        "print(\"tfs22 : \",tfs22.shape)\n",
        "print(\"tfs23 : \",tfs23.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeCf2rE4sdMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lihat hasil proses\n",
        "feature_names22 = tfidf22.get_feature_names()\n",
        "print('Jumlah bigram relevan: ', len(feature_names22))\n",
        "print('bigram temuan: ', feature_names22)\n",
        "\n",
        "feature_names23 = tfidf23.get_feature_names()\n",
        "print('\\nJumlah bi/trigram relevan: ', len(feature_names23))\n",
        "print('bi/trigram temuan: ', feature_names23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ub4kqjQs32f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print idf values\n",
        "df_idf22 = pd.DataFrame(tfidf22.idf_, index=feature_names22,columns=[\"tf-idf\"])\n",
        "\n",
        "# sort ascending\n",
        "df_idf22 = df_idf22.sort_values(by=['tf-idf'])\n",
        "\n",
        "print(\"TF_IDF bigram:\")\n",
        "print(df_idf22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GQZC_M9tHu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print idf values\n",
        "df_idf23 = pd.DataFrame(tfidf23.idf_, index=feature_names23,columns=[\"tf-idf\"])\n",
        "\n",
        "# sort ascending\n",
        "df_idf23 = df_idf23.sort_values(by=['tf-idf'])\n",
        "\n",
        "print(\"TF_IDF bi/trigram:\")\n",
        "print(df_idf23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBNGhaejrgqj",
        "colab_type": "text"
      },
      "source": [
        "## Step 04 : Fine Tuning Stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNtRZQ6drnDA",
        "colab_type": "text"
      },
      "source": [
        "Kita bisa memanfaatkan hasil kalkukasi awal TF IDF untuk memperbaiki proses selanjutnya agar lebih relevan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO-Xyh4rrwfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Sebelum fine tune : \", len(stopwords))\n",
        "stopwords_finetune = {\"diarium\",\"fitur\",\"telkom\",\"ok\",\"dll\"}\n",
        "\n",
        "stopwords_all.extend(stopwords_finetune)\n",
        "print(\"Setelah fine tune : \", len(stopwords))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo3SvFckvJNc",
        "colab_type": "text"
      },
      "source": [
        "Uji hasil fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHfj9-qgu-GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perform tf-idf vectorization\n",
        "tfidf22 = TfidfVectorizer(max_df=0.8,             # terms with document frequency value > 0.8 will be removed (terlalu sering muncul)\n",
        "                        min_df=0.006,           # terms with document frequency value < 0.008 will be removed (terlalu jarang)\n",
        "                        max_features=200000,    # create maximum 200.000 vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
        "                        stop_words = stopwords, # stopwords list\n",
        "                        use_idf=True,           # enable inverse-document-frequency reweighting\n",
        "                        tokenizer=text_preprocessing, # override the string tokenization step by using text_prepocessing function \n",
        "                        ngram_range=(2,2))      # ngram range 1 - 2 (unigram=1, bigram=2, trigram=3)\n",
        "\n",
        "tfs22 = tfidf22.fit_transform(token_dict.values())\n",
        "\n",
        "# Cek tabel perhitungan. Tabel berisi rows=jumlah dokumen, columns=jumlah kata\n",
        "print(\"tfs22 shape : \",tfs22.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49BaOXUpveUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lihat hasil proses\n",
        "feature_names22 = tfidf22.get_feature_names()\n",
        "print('Jumlah bigram relevan: ', len(feature_names22))\n",
        "print('bigram temuan: ', feature_names22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twp6HT80vgUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print idf values\n",
        "df_idf22 = pd.DataFrame(tfidf22.idf_, index=feature_names22,columns=[\"tf-idf\"])\n",
        "\n",
        "# sort ascending\n",
        "df_idf22 = df_idf22.sort_values(by=['tf-idf'])\n",
        "\n",
        "print(\"TF_IDF bigram:\")\n",
        "print(df_idf22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCaud76HkORs",
        "colab_type": "text"
      },
      "source": [
        "## Step 05 : Transformasi TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqzCPghikyZI",
        "colab_type": "text"
      },
      "source": [
        "Kita bisa mengguakan model hasil proses untuk mengecek kemunculan term penting hasil kalkulasi di dokumen lain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUu9zNd4keN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str1 = 'Update aplikasi jika bisa dipermudah. Kalau bisa hanya dengan satu tombol update. Saat ini agak repot jika untuk update aplikasi prosesnya seperti download - install ulang.'\n",
        "response = tfidf22.transform([str1])\n",
        "#show result\n",
        "print('\\nHasil temuan str1:')\n",
        "for col in response.nonzero()[1]:\n",
        "    print (feature_names22[col], ' - ', response[0, col])\n",
        "print('\\nHasil response :', response.shape)\n",
        "print('Hasil preprocess str1: ', text_preprocessing(str1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ME_6bdr8fuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str2 = '1. Info rekan = plis searching nya dipermudah (membaca keyword nya) 2. kalau update tolong yang lebih user friendly tanpa harus uninstall APK yang eksisting 3. HC Wiki = keyword nya diperbanyak'\n",
        "response2 = tfidf22.transform([str2])\n",
        "\n",
        "print('\\nHasil temuan str2:')\n",
        "for col in response2.nonzero()[1]:\n",
        "    print (feature_names22[col], ' - ', response2[0, col])\n",
        "print('\\nHasil response:', response2.shape)\n",
        "print('Hasil preprocess str2: ', text_preprocessing(str2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}